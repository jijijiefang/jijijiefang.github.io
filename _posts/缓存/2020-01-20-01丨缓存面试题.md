---
layout:     post
title:      "缓存-01丨缓存面试题"
date:       2020-01-20 21:28:27
author:     "jiefang"
header-style: text
tags:
    - 缓存
---
# 缓存面试题
### 用了缓存之后，有哪些常见问题？
常见的问题，可列举如下：

- 写入问题
    - 缓存何时**写入**？并且写时如何避免并发重复写入？
    - 缓存如何**失效**？
    - 缓存和 DB 的**一致性**如何保证？
- 经典三连问
    - 如何避免**缓存穿透**的问题？
    - 如何避免**缓存击穿**的问题？
    - 如果避免**缓存雪崩**的问题？

### 如何避免缓存”穿透”的问题？
>缓存穿透:是指查询一个一定**不存在**的数据，由于缓存是不命中时被动写，并且处于容错考虑，如果从DB查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到DB去查询，失去了缓存的意义。
![image](https://s2.ax1x.com/2020/01/19/1PFkQJ.png)

- MySQL 的性能是远不如 Redis 的，如果大量的请求直接打到 MySQL ，则会直接打挂 MySQL;
- 缓存穿透不一定是攻击，也可能是程序问题，疯狂读取不存在的数据，又或者“无脑”的爬虫，顺序爬取数据。
- 一定要注意，缓存穿透，指的是查询一个不存在的数据，容易和缓存击穿混淆。

#### 如何解决
- 缓存空对象:当从DB查询数据为空，我们仍然将这个空结果进行缓存，具体的值需要使用特殊的标识，能和真正缓存的数据区分开。另外，需要设置较短的过期时间，一般建议不要超过 5 分钟。
- BloomFilter布隆过滤器:在缓存服务的基础上，构建 BloomFilter 数据结构，在BloomFilter中存储对应的KEY是否存在，如果存在，说明该 KEY 对应的值不为空。流程为：
    - 根据 KEY 查询【BloomFilter缓存】。如果不存在对应的值，直接返回；如果存在，继续向下执行；
    - 根据 KEY 查询在【数据缓存】的值。如果存在值，直接返回；如果不存在值，继续向下执行；
    - 查询 DB 对应的值，如果存在，则更新到缓存，并返回该值；
- BloomFilter 存在误判：就是存在的不一定存在，不存在的一定不存在。这样就会导致，一个存在的 KEY 被误判成不存在。
- 同时，BloomFilter 不允许删除。例如说，一个 KEY 一开始是不存在的，后来数据新增了，但是 BloomFilter 不允许删除的特点，就会导致一直会被判断成不存在。

### 如何避免缓存”雪崩”的问题？
缓存雪崩：是指缓存由于某些原因无法提供服务( 例如，缓存挂掉了 )，所有请求全部达到 DB 中，导致 DB 负荷大增，最终挂掉的情况。

#### 如何解决
- 缓存高可用：通过搭建缓存的高可用，避免缓存挂掉导致无法提供服务的情况，从而降低出现缓存雪崩的情况。假设使用 Redis 作为缓存，则可以使用 Redis Sentinel 或 Redis Cluster 实现高可用。
- 本地缓存：如果使用本地缓存时，即使分布式缓存挂了，也可以将 DB 查询到的结果缓存到本地，避免后续请求全部到达 DB 中。
    - 本地缓存的实时性怎么保证？
    - 引入消息队列。在数据更新时，发布数据更新的消息；而进程中有相应的消费者消费该消息，从而更新本地缓存。
    - 设置较短的过期时间，请求时从 DB 重新拉取。
    - 可以使用 Ehcache、Guava Cache 实现本地缓存的功能。
- 请求 DB 限流：通过限制 DB 的每秒请求数，避免把 DB 也打挂了。
- 可以使用 Guava RateLimiter、Sentinel、Hystrix 实现限流的功能。

### 如何避免缓存”击穿”的问题？
缓存击穿：是指某个**极度“热点”数据**在某个时间点过期时，恰好在这个时间点对这个 KEY 有大量的并发请求过来，这些请求发现缓存过期一般都会从 DB 加载数据并回设到缓存，但是这个时候大并发的请求可能会瞬间 DB 压垮。
- 对于一些设置了过期时间的KEY，如果这些KEY可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。
- 区别：
    - 和缓存“雪崩“”的区别在于，前者针对某一 KEY缓存，后者则是很多 KEY 。
    - 和缓存“穿透“”的区别在于，这个 KEY 是真实存在对应的值的。

#### 如何解决
- 使用互斥锁：请求发现缓存不存在后，去查询 DB 前，使用分布式锁，保证有且只有一个线程去查询 DB ，并更新到缓存。流程如下：
    - 获取分布式锁，直到成功或超时。如果超时，则抛出异常，返回。如果成功，继续向下执行。
    - 获取缓存。如果存在值，则直接返回；如果不存在，则继续往下执行。
    - 查询 DB ，并更新到缓存中，返回值。
- 手动过期：缓存上从不设置过期时间，功能上将过期时间存在 KEY 对应的 VALUE 里。流程如下：
    - 获取缓存。通过VALUE的过期时间，判断是否过期。如果未过期，则直接返回；如果已过期，继续往下执行。
    - 通过一个后台的异步线程进行缓存的构建，也就是“手动”过期。通过后台的异步线程，保证有且只有一个线程去查询 DB。
    - 同时，虽然 VALUE已经过期，还是直接返回。通过这样的方式，保证服务的可用性，虽然损失了一定的时效性。

### 缓存和 DB 的一致性如何保证？
主要有两种情况，会导致缓存和 DB 的一致性问题：
- 并发的场景下，导致读取老的 DB 数据，更新到缓存中。
    >主要指的是，更新 DB 数据之前，先删除 Cache 的数据。在低并发量下没什么问题，但是在高并发下，就会存在问题。在(删除 Cache 的数据, 和更新 DB 数据)时间之间，恰好有一个请求，我们如果使用被动读，因为此时 DB 数据还是老的，又会将老的数据写入到 Cache 中。
- 缓存和 DB 的操作，不在一个事务中，可能只有一个 DB 操作成功，而另一个 Cache 操作失败，导致不一致。

#### 解决方案
- 将缓存可能存在的并行写，实现串行写。
- 实现数据的最终一致性。

- 先淘汰缓存，再写数据库:先淘汰缓存，数据的最终一致性是可以得到有效的保证的。先淘汰缓存，即使写数据库发生异常，也就是下次缓存读取时，多读取一次数据库。这种方案会存在缓存和 DB的数据会不一致的情况.
    - 解决缓存并行写，实现串行写,引入分布式锁:
    - 在写请求时，先淘汰缓存之前，先获取该分布式锁。
    - 在读请求时，发现缓存不存在时，先获取分布式锁。
    - 写请求时，是否主动更新缓存，根据业务需要。
- 先写数据库，再更新缓存：按照“先写数据库，再更新缓存”，要保证 DB 和缓存的操作，能够在“同一个事务”中，从而实现最终一致性。
    - 基于定时任务来实现：
        - 首先，写入数据库。
        - 然后，在写入数据库所在的事务中，插入一条记录到任务表。该记录会存储需要更新的缓存 KEY 和 VALUE 。
        - 最后，定时任务每秒扫描任务表，更新到缓存中，之后删除该记录。
    - 基于消息队列来实现：
        - 首先，写入数据库。
        - 然后，发送带有缓存KEY和VALUE的事务消息。此时，需要有支持事务消息特性的消息队列，或者自己封装消息队列，支持事务消息。
        - 最后，消费者消费该消息，更新到缓存中。
- 基于数据库的 binlog 日志
    ![image](https://s2.ax1x.com/2020/01/19/1Pk0N6.png)
    - 应用直接写数据到数据库中。
    - 数据库更新binlog日志。
    - 利用Canal中间件读取binlog日志。
    - Canal借助于限流组件按频率将数据发到MQ中。
    - 应用监控MQ通道，将MQ的数据更新到Redis缓存中。

### 什么是缓存预热？如何实现缓存预热？
缓存预热:在刚启动的缓存系统中，如果缓存中没有任何数据，如果依靠用户请求的方式重建缓存数据，那么对数据库的压力非常大，而且系统的性能开销也是巨大的。此时，最好的策略是启动时就把热点数据加载好。这样，用户请求时，直接读取的就是缓存的数据，而无需去读取 DB 重建缓存数据。

#### 如何实现
几种方式来实现：
- 据量不大时，项目启动时，自动进行初始化。
- 写个修复数据脚本，手动执行该脚本。
- 写个管理界面，可以手动点击，预热对应的数据到缓存中。

### 缓存数据的淘汰策略有哪些？
除了缓存服务器自带的缓存自动失效策略之外，我们还可以根据具体的业务需求进行自定义的“手动”缓存淘汰，常见的策略有两种：

- 定时去清理过期的缓存。
- 当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。
两者各有优劣，第一种的缺点是维护大量缓存的 key 是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂.

### 缓存如何存储 POJO 对象？
实际场景下，缓存值可能是一个 POJO 对象，就需要考虑如何 POJO 对象存储的问题。目前有两种方式：

- 方案一，将 POJO 对象序列化进行存储，适合 Redis 和 Memcached 。
    - 对于 POJO 对象比较大，可以考虑使用压缩算法，例如说 Snappy、zlib、GZip 等等。
- 方案二，使用 Hash 数据结构，适合 Redis 。